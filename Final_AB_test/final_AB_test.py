#!/usr/bin/env python
# coding: utf-8

# <h1>Table of Contents<span class="tocSkip"></span></h1>
# <div class="toc"><ul class="toc-item"><li><span><a href="#Импорт-библиотек,-открытие-файлов" data-toc-modified-id="Импорт-библиотек,-открытие-файлов-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Импорт библиотек, открытие файлов</a></span></li><li><span><a href="#Знакомство-с-данными.-Предобработка" data-toc-modified-id="Знакомство-с-данными.-Предобработка-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Знакомство с данными. Предобработка</a></span><ul class="toc-item"><li><span><a href="#project" data-toc-modified-id="project-2.1"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>project</a></span></li><li><span><a href="#new_users" data-toc-modified-id="new_users-2.2"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>new_users</a></span></li><li><span><a href="#participants" data-toc-modified-id="participants-2.3"><span class="toc-item-num">2.3&nbsp;&nbsp;</span>participants</a></span></li><li><span><a href="#events" data-toc-modified-id="events-2.4"><span class="toc-item-num">2.4&nbsp;&nbsp;</span>events</a></span></li><li><span><a href="#Выводы" data-toc-modified-id="Выводы-2.5"><span class="toc-item-num">2.5&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href="#Оценка-корректности-проведения-теста" data-toc-modified-id="Оценка-корректности-проведения-теста-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Оценка корректности проведения теста</a></span><ul class="toc-item"><li><span><a href="#Проверка-аудитории-теста" data-toc-modified-id="Проверка-аудитории-теста-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>Проверка аудитории теста</a></span><ul class="toc-item"><li><span><a href="#Пересечение-с-конкурирующим-тестом" data-toc-modified-id="Пересечение-с-конкурирующим-тестом-3.1.1"><span class="toc-item-num">3.1.1&nbsp;&nbsp;</span>Пересечение с конкурирующим тестом</a></span></li><li><span><a href="#Проверка-на-вхождение-в-обе-группы,-равномерность-распределения-по-группам" data-toc-modified-id="Проверка-на-вхождение-в-обе-группы,-равномерность-распределения-по-группам-3.1.2"><span class="toc-item-num">3.1.2&nbsp;&nbsp;</span>Проверка на вхождение в обе группы, равномерность распределения по группам</a></span></li></ul></li><li><span><a href="#Проверка-дат" data-toc-modified-id="Проверка-дат-3.2"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>Проверка дат</a></span><ul class="toc-item"><li><span><a href="#Пользователи,-пришедшие-после-окончания-набора-новых-пользователей" data-toc-modified-id="Пользователи,-пришедшие-после-окончания-набора-новых-пользователей-3.2.1"><span class="toc-item-num">3.2.1&nbsp;&nbsp;</span>Пользователи, пришедшие после окончания набора новых пользователей</a></span></li><li><span><a href="#События,-совершенные-до-старта-теста-или-после-его-окончания" data-toc-modified-id="События,-совершенные-до-старта-теста-или-после-его-окончания-3.2.2"><span class="toc-item-num">3.2.2&nbsp;&nbsp;</span>События, совершенные до старта теста или после его окончания</a></span></li></ul></li><li><span><a href="#Распределение-пользователей-по-регионам" data-toc-modified-id="Распределение-пользователей-по-регионам-3.3"><span class="toc-item-num">3.3&nbsp;&nbsp;</span>Распределение пользователей по регионам</a></span><ul class="toc-item"><li><span><a href="#Проверка-пересечения-времени-теста-с-региональными-маркетинговыми-активностями" data-toc-modified-id="Проверка-пересечения-времени-теста-с-региональными-маркетинговыми-активностями-3.3.1"><span class="toc-item-num">3.3.1&nbsp;&nbsp;</span>Проверка пересечения времени теста с региональными маркетинговыми активностями</a></span></li></ul></li><li><span><a href="#Все-ли-пользователи-осуществляли-действия?" data-toc-modified-id="Все-ли-пользователи-осуществляли-действия?-3.4"><span class="toc-item-num">3.4&nbsp;&nbsp;</span>Все ли пользователи осуществляли действия?</a></span></li><li><span><a href="#Ограничение-действий-по-лайфтайму" data-toc-modified-id="Ограничение-действий-по-лайфтайму-3.5"><span class="toc-item-num">3.5&nbsp;&nbsp;</span>Ограничение действий по лайфтайму</a></span></li><li><span><a href="#Оценка-оставшихся-пользователей" data-toc-modified-id="Оценка-оставшихся-пользователей-3.6"><span class="toc-item-num">3.6&nbsp;&nbsp;</span>Оценка оставшихся пользователей</a></span></li><li><span><a href="#Выводы" data-toc-modified-id="Выводы-3.7"><span class="toc-item-num">3.7&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href="#Исследовательский-анализ" data-toc-modified-id="Исследовательский-анализ-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Исследовательский анализ</a></span><ul class="toc-item"><li><span><a href="#Распределение-количества-событий-на-пользователя" data-toc-modified-id="Распределение-количества-событий-на-пользователя-4.1"><span class="toc-item-num">4.1&nbsp;&nbsp;</span>Распределение количества событий на пользователя</a></span></li><li><span><a href="#Число-событий-по-дням" data-toc-modified-id="Число-событий-по-дням-4.2"><span class="toc-item-num">4.2&nbsp;&nbsp;</span>Число событий по дням</a></span></li><li><span><a href="#Как-меняется-конверсия-в-воронке-в-выборках-на-разных-этапах" data-toc-modified-id="Как-меняется-конверсия-в-воронке-в-выборках-на-разных-этапах-4.3"><span class="toc-item-num">4.3&nbsp;&nbsp;</span>Как меняется конверсия в воронке в выборках на разных этапах</a></span><ul class="toc-item"><li><span><a href="#Кумулятивные-конверсии" data-toc-modified-id="Кумулятивные-конверсии-4.3.1"><span class="toc-item-num">4.3.1&nbsp;&nbsp;</span>Кумулятивные конверсии</a></span></li></ul></li><li><span><a href="#Доли-целевых-действий-в-каждый-из-лайфтаймов" data-toc-modified-id="Доли-целевых-действий-в-каждый-из-лайфтаймов-4.4"><span class="toc-item-num">4.4&nbsp;&nbsp;</span>Доли целевых действий в каждый из лайфтаймов</a></span></li><li><span><a href="#Выводы" data-toc-modified-id="Выводы-4.5"><span class="toc-item-num">4.5&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href="#Статистический-анализ" data-toc-modified-id="Статистический-анализ-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Статистический анализ</a></span></li><li><span><a href="#Выводы,-решение-по-тесту" data-toc-modified-id="Выводы,-решение-по-тесту-6"><span class="toc-item-num">6&nbsp;&nbsp;</span>Выводы, решение по тесту</a></span></li></ul></div>

# # A/B тестирование
# Даны 4 датасета с информамцией о пользователях, их действиях, разбивке на группы А/В-тестов и календарь маркетингов мероприятий. 
# **Необходимо проанализировать А/В-тестирование. Основные задачи:**
# * оценка корректности проведения теста
# * проверка статистической разницы долей z-критерием
# * анализ результатов теста
# 
# # Техническое задание
# * **Название теста:** recommender_system_test ;
# * **группы:** А — контрольная, B — новая платёжная воронка;
# * **дата запуска:** 2020-12-07;
# * **дата остановки набора новых пользователей:** 2020-12-21;
# * **дата остановки:** 2021-01-04;
# * **аудитория:** в тест должно быть отобрано 15% новых пользователей из региона EU;
# * **назначение теста:** тестирование изменений, связанных с внедрением улучшенной рекомендательной системы;
# * **ожидаемое количество участников теста:** 6000.
# * **ожидаемый эффект:** за 14 дней с момента регистрации пользователи покажут улучшение каждой метрики не менее, чем на 10%: конверсии в просмотр карточек товаров — событие product_page , просмотры корзины — product_cart , покупки — purchase .
# 
# 
# # Описание данных
# **1. ab_project_marketing_events.csv** — календарь маркетинговых событий на 2020 год. Структура файла:
# * name — название маркетингового события;
# * regions — регионы, в которых будет проводиться рекламная кампания;
# * start_dt — дата начала кампании;
# * finish_dt — дата завершения кампании.
# 
# **2. final_ab_new_users.csv** — пользователи, зарегистрировавшиеся с 7 до 21 декабря 2020 года. Структура файла:
# * user_id — идентификатор пользователя;
# * first_date — дата регистрации;
# * region — регион пользователя;
# * device — устройство, с которого происходила регистрация
# 
# **3. final_ab_events.csv** — действия новых пользователей в период с 7 декабря 2020 по 4 января 2021 года. Структура файла:
# * user_id — идентификатор пользователя;
# * event_dt — дата и время события;
# * event_name — тип события;
# * details — дополнительные данные о событии. Например, для покупок, purchase, в этом поле хранится стоимость покупки в долларах.
# 
# **4. final_ab_participants.csv — таблица участников тестов. Структура файла:**
# * user_id — идентификатор пользователя;
# * ab_test — название теста;
# * group — группа пользователя.
# 
# # План работы
# 
# 1. Импорт необходимых библиотек, открытие датасетов
# 2. Предобрабтка данных:
#     * обработка пропусков, дубликатов, приведение данных к корректным типам
# 3. Оценка корректности проведения теста в соответствии с ТЗ и общими принципами корректности. Проверка:
#     * аудитории теста 
#         * пересечение с конкурирующим тестом
#         * пересечениепо группам теста
#         * равномерность распределения учсатников по группам
#     * дат
#         * нет ли пользователей, пришедших после даты окончания набора новых 
#         * нет ли действий, совершенных до старта теста и после его окончания
#     * распределения пользователей по регионам
#         * достаточное ли количество участников из EU
#         * есть ли пересечение с региональными маркетинговыми активностями
#     * наличия совершенных действий у каждого пользователя
#     * лайфтайм
#         * все ли пользователи успели "прожить" 14 дней?
#         * есть ли действия, совершенные после 14-го лайфтайма?
#     * оценка оставшихся участников тестов
#     * характеристика корректности проведения теста
# 4. Исследовательский анализ данных:
#     * как распрделены события по пользователям в выборках
#     * как число событий в выборках распределено по дням
#     * как отличаются конверсии двух групп, наблюдается ли относительный прирост группы В по отношению к А
#     * какие особенности данных нужно учесть, прежде чем приступать к А/В-тестированию
# 5. Оценка результатов А/В-тестирования
#     * что можно сказать про результаты  А/В-тестирования
#     * проверка статистической разницы долей z-критерием
#     * выводы и общее заключение о корректности проведения теста.

# ## Импорт библиотек, открытие файлов

# In[1]:


import pandas as pd

import datetime as dt
from datetime import timedelta

import numpy as np 

from scipy import stats as st

import math as mth

import matplotlib.pyplot as plt
plt.style.use('ggplot')
get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")

import plotly
import plotly.express as px
from plotly import graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as io
io.templates.default = 'ggplot2'

io.renderers.default = "png" 
svg_renderer = io.renderers["png"] 
svg_renderer.scale = 1.2


# In[2]:


try:
    project = pd.read_csv(r'\Users\Hp\Desktop\Практикум\FINAL\ab_project_marketing_events.csv') 
    new_users = pd.read_csv(r'\Users\Hp\Desktop\Практикум\FINAL\final_ab_new_users.csv') 
    participants = pd.read_csv(r'\Users\Hp\Desktop\Практикум\FINAL\final_ab_participants.csv') 
    events = pd.read_csv(r'\Users\Hp\Desktop\Практикум\FINAL\final_ab_events.csv') 
except:
    project = pd.read_csv('https://code.s3.yandex.net/datasets/ab_project_marketing_events.csv')
    new_users = pd.read_csv('https://code.s3.yandex.net/datasets/final_ab_new_users.csv')
    participants = pd.read_csv('https://code.s3.yandex.net/datasets/final_ab_participants.csv')
    events = pd.read_csv('https://code.s3.yandex.net/datasets/final_ab_events.csv')


# In[3]:


display(project.head(3))
display(new_users.head(3))
display(participants.head(3))
events.head(3)


# **Все таблицы загружены**

# ## Знакомство с данными. Предобработка

# На этом этапе мы посмотрим на то, какие данные хранят таблицы, обработаем пропуски и дубликаты при необходимости, приведем данные к корректным типам. **Пересечения групп, соответствие дат и другие характеристики для оценки корректности проведения А/В-теста будут проанализированы в соответствующем блоке**

# ### project

# In[4]:


display(project)
project.info()


# `Таблица включает всего 14 строк,` пропусков и дубликатов нет, столбцы имеют корректное название
# * приведем столбцы с датой к корректному типу
# * заменим 'N.America' на общепринятую аббревиатуру NA

# In[5]:


# заменяем все 'N.America' в столбце 'regions'
project['regions'] = [elem.replace("N.America", "NA", 1) for elem in project['regions']]
#приводим тип данных в столбцах с датой к корректному:
project['start_dt'] = pd.to_datetime(project['start_dt'])
project['finish_dt'] = pd.to_datetime(project['finish_dt'])


# **Таблица project готова**

# ### new_users

# In[6]:


display(new_users.head())
new_users.info()


# `Таблица содержит 61733 наблюдения,` пропусков нет, столбцы имеют корректные названия
# * проверим наличие строк-дубликатов, дубликатов в столбце 'user_id'
# * приведем столбец с датой к корректному типу
# * выявим временной промежуток
# * проверим значения в столбцах с категориальными данными, обработаем неявные дубликаты при наличии

# In[7]:


print('Число строк-дубликатов:', new_users.duplicated().sum())
print("Число дубликатов в столбце 'user_id':", new_users['user_id'].duplicated().sum())


# In[8]:


# приводим столбец с датой к корректному типу, выявляем временной промежуток:
new_users['first_date'] = pd.to_datetime(new_users['first_date'])
print('Минимальная дата:', new_users['first_date'].min())
print('Максимальная дата:', new_users['first_date'].max())
print('Временной диапазон:', new_users['first_date'].max()-new_users['first_date'].min())


# Минимальная дата соответствует дате запуска теста, `максимальная превышает дату остановки набора новых пользователей.` На этом этапе просто фиксируем временной промежуток, главное, что не наблдюдаем каких-то слишком выбивающихся дат.
# 
# `Проверим категориальные данные`

# In[9]:


print("Уникальные значения в столбце 'region':", new_users['region'].sort_values().unique().tolist())


# `Неявных дубликатов не обнаружили,` заменим "N.America" по аналогии с предыдущим пунктом и посмотрим как распределены данные по регионам.

# In[10]:


# заменяем все 'N.America' в столбце 'region'
new_users['region'] = [elem.replace("N.America", "NA", 1) for elem in new_users['region']]
new_users['region'].value_counts()


# Большинство наших пользователей из `европейского региона.`

# In[11]:


print("Уникальные значения в столбце 'device':",new_users['device'].sort_values().unique().tolist())
new_users['device'].value_counts()


# `Неявных дубликатов нет,` большинство клиентов используют Android.
# 
# **Таблица 'new_users' готова**

# ### participants

# In[12]:


display(participants.head())
participants.info()


# `Таблица содержит 18268 наблдюдений,` пропусков нет, типы данных корректные, столбцы имеют корректные названия.
# * проверим наличие строк-дубликатов, дубликатов в столбце 'user_id'
# * проверим какие значения хранятся в столбцах с категориальными данными

# In[13]:


print('Число строк-дубликатов:',participants.duplicated().sum())
print('Число дубликатов "user_id":', participants['user_id'].duplicated().sum())
print('Число дубликатов в связке "user_id"-"ab_test":', participants[['user_id', "ab_test"]].duplicated().sum())


# Видим 1602 дубликатов в столбце 'user_id' - `пользователи участвуют в обоих тестах одновременно.` На этом этапе фиксируем наличие таких пользователей, детально будем рассматривать при оценке корректности теста. Строк-дубликатов нет.
# 
# **Проверим категориальные данные**

# In[14]:


print("Уникальные значения в столбце 'group':",participants['group'].sort_values().unique().tolist())
print("Уникальные значения в столбце 'ab_test':",participants['ab_test'].sort_values().unique().tolist())


# Здесь никаких сюрпризов, `пользователи разбиты на две группы, встречается два теста:` исследуемый ('recommender_system_test) и второй, конкурирующий ('interface_eu_test'). `Посмотрим как распределены пользователи в исследуемом тесте по группам:`

# In[15]:


participants.query('ab_test  == "recommender_system_test"')['group'].value_counts()


# `Есть пользователи в обеих группах,` группа А имеет численное преимущество.
# 
# **Таблица готова к работе**

# ### events

# In[16]:


display(events.head())
events.info()


# `Таблица включает 440317 наблюдений,` столбец 'details' содержит пропуски, столбец с датой хранит данные с некорректным типом.
# * проверим наличие строк-дубликатов
# * приведем столбец с датой к корректному типу данных
# * добавим столбец 'date' с датой без времени
# * выявим временной промежуток
# * изучим значения, хранящиеся в столбце 'event_name'
# * изучим пропуски в столбце 'details'
# * сверим совпдание user_id с одноименным столбцом в таблице 'new_users'

# In[17]:


print('Число строк-дубликатов:',events.duplicated().sum())
print('Число дубликатов в связке "user_id"-"event_dt":', events[['user_id', "event_dt"]].duplicated().sum())


# Явных дубликатов не обнаружено, видим большое количество дубликатов в связке id-время события, объясняется тем, что если в браузере у пользователя отключена часть необходимого тесту функционала события могут записываться с одинаковым временем завершения сессии.

# In[18]:


# приводим столбец с датой к корректному типу, добавляем столбец с датой, выявляем временной промежуток:
events['event_dt'] = pd.to_datetime(events['event_dt'])
events['date'] = events['event_dt'].astype('datetime64[D]')
print('Минимальная дата:', events['event_dt'].min())
print('Максимальная дата:',events['event_dt'].max())
print('Временной диапазон:', events['event_dt'].max() - events['event_dt'].min())


# Минимальныя и максимальная даты вписываются во временой промежуток проведения А/В-теста.

# In[19]:


print("Уникальные значения в столбце 'event_name':", events['event_name'].unique().tolist())
events['event_name'].value_counts()


# Всего встречается 4 типа событий. Видим, что событие "просмотр корзины" случается реже, чем "покупка", что сразу наталкивает на мысль, что "product_cart" - необязательное событие перед "purchase", скорее всего, возможна оплата без добавления в корзину. В остальном данные распределены нормально.
# 
# **Изучим столбец 'details'**

# In[20]:


events['details'].value_counts()


# Всего 4 вида значений, суммы покупок фиксированные. Посмотрим, по каким типам событий встречаются пропуски в 'details'

# In[21]:


print("Пропуски в 'details' характерны для событий:", events.query('details.isna()')['event_name'].unique().tolist())
print("Столбец 'details' заполнен для события:", events.query('details.notna()')['event_name'].unique().tolist())


# Все логично, столбец заполнен данными о стоимости покупки, для остальных событий встречаются пропуски.
# 
# **Таблица готова к работе**

# ### Выводы

# * обработаны 4 датасета
# * встречаются пропущенные значения в столбце 'details' таблицы 'events' - объясняется типом совершенного действия (в столбце заполнены данные только для покупок)
# * явных дубликатов нет ни в одном датасете
# * встречаются дубликаты в таблице 'events' в связке столбцов "user_id"-"event_dt" - объясняется техническими особенностями
# * встречаются дублирующиеся 'user_id'  таблице 'participants' - пользователи участвуют в двух тестах одновременно, изучим детальнее при проведении оценки корректности
# * в исследуемом тесте есть пользователи из обеих групп
# * все даты приведены к корректному типу
# 
# **Все 4 датасета готовы к дальнейшему анализу**

# ## Оценка корректности проведения теста

# Оценим корректность проведения теста. Проверим соответствие техническому заданию и общие признаки корректности разбивки на группы. **Определим следующий план оценки корректности:**
# 
# **1. Проверка аудитории теста:**
# 
# * пересечение пользователей:
#     * с конкуририующим тестом: как распределены участники конкурирующего теста по группам исследуемого теста, корректно ли оставлять их при анализе исследуемого A/B-теста
#     * по группам исследуемого теста: нет ли пользователей, входящих в две группы одновременно
# * оценка равномерности распределения пользователей по группам
#     
# **2. Проверка дат:**
# 
# * первая дата пользователя должна попадать в диапазон даты запуска теста и даты остановки набора новых пользователей
# * дата события не должна превышать дату остановки теста
# * совпадает ли время проведения теста с маркетинговыми и другими активностями
# 
# **3. Распределение пользователей по регионам**
# * Проверка пересечения времени теста с региональными маркетинговыми активностями
# 
# **4. Все ли пользователи соврешали действия?**
# 
# **5. Лайфтайм**
# * все ли пользователи успели "прожить" 14 дней? 
# * есть ли действия, совершенные после 14-го лайфтайма?
# 
# **6. Оценка оставшихся участников тестов**
# 
# *выполняется после всех предудщих проверок, т.к. возможны исключения некоторых пользователей из теста*
# 
# * соответствует ли количество участников теста ожидаемому (6000 пользователей)
# * соответсвует ли доля пользователей из EU сожидаемой (15%)
# 
# **7. Характеристика корректности проведения теста**

# ### Проверка аудитории теста

# #### Пересечение с конкурирующим тестом

# На этапе предобработки данных мы обратили внимание, что 1602 пользователя участвуют в обоих тестах одновременно. Изучим это пересечение внимательнее.

# In[22]:


# считаем по каждому пользователю количество тестов
test_cnt = participants.groupby('user_id')['ab_test'].nunique().sort_values(ascending=False).reset_index()
# сохраняем в список пользователей, участвующих в двух тестах
double_test_users = test_cnt.query('ab_test > 1')['user_id'].tolist()
# В 'double_test_competing' сохраняем информацию по таким пользователям, оставляем только конкурирующий тест
double_test_competing = participants.query('ab_test == "interface_eu_test" and user_id in @double_test_users')

print('Всего пользователей участвующих в тестах:', participants['user_id'].nunique())
print('Пользователей, участвующих в исследуемом тесте:', participants.query('ab_test == "recommender_system_test"')
      ['user_id'].nunique())
print('Пользователей, участвующих в обеих тестах одновременно:', len(double_test_users))


# Большинство новых пользователей участвуют в конкурирующем тесте, в исследуемом **"recommender_system_test" участвует всего 6701 пользователь, среди них 1602 человека участвует в двух тестах одновременно.**
# 
# Два теста на одних и тех же пользователей в целом проводить не следует, предпочтительнее исключить "пересекающихся" пользователей, но тогда мы потеряем слишком много участников. **Посмотрим как распределены участники двух тестов одновременно по группам конкурирующего теста:**

# In[23]:


print('Пользователи, участвующих в обоих тестах: распределение по группам конкурирующего теста:')
double_test_competing['group'].value_counts()


# **Пользователей, участвующих в группе А конкурирующего теста можно оставить.** В тесте "interface_eu_test" для них не транслировались никакие изменения и результаты конкурирующего теста не должны повлиять на результаты нашего теста.
# 
# **С пользователями, участвующими в группе В конкурирующего теста, ситуация сложнее.** В этом тесте для них транслировались изменения и мы не можем определить что именно влияло на их поведение, соответственно, не можем корректно проанализировать результаты исследуемого теста. **Посмотрим, равномерно ли распределены такие пользователи по группам теста "recommender_system_test"**

# In[24]:


# собираем пользователей, участвующих в обеих теста и входящих в группу В в конкурирующем тесте, 
# фильтруем по ним ''participants:
double_test_competing_b = double_test_competing.query('group=="B"')['user_id'].tolist()
participants.query('user_id in @double_test_competing_b and ab_test == "recommender_system_test"')['group'].value_counts()


# В группе А таких пользователей больше, однако мы помним, что в исследуемом тесте в принципе численное преимещество за группой А. Единственный способ оценить равномерны ли доли таких участников в обеих группах: **провести z-тест и оценить разницу долей.** 
# 
# Используем самостоятельно созданную функцию **'get_z_test'** - она пригодится нам в дальнейшем для оценки конверсий. Функция принимает количество "успехов" в обеих группах, количество "попыток" и уровень стат.значимости. **Передадим ей число участников группы B конкурирующего теста, попавших в группы А и B исследуемого теста, а так же общее число участников исследумого теста по группам.**
# 
# *В нашем случае под "конверсией" понимаем долю участников*

# In[25]:


# подсчитываем количество участников группы B конкурирующего теста в каждой из групп исследуемого теста:
competing_b_recommender_A = participants.query('user_id in @double_test_competing_b                                                and ab_test == "recommender_system_test" and group=="A"')['user_id'].nunique()
competing_b_recommender_B = participants.query('user_id in @double_test_competing_b                                                and ab_test == "recommender_system_test" and group=="B"')['user_id'].nunique()
#подсчитываем общее количество участников по группам исследуемого теста:
recommender_A = participants.query('ab_test == "recommender_system_test" and group=="A"')['user_id'].nunique()
recommender_B = participants.query('ab_test == "recommender_system_test" and group=="B"')['user_id'].nunique()


# * **H0** Участники из группы B конкурируещего теста **равномерно** распределены по группам исследуемого теста (группы равны)
# * **H1** Участники из группы B конкурируещего теста **неравномерно** распределены по группам исследуемого теста (группы не равны)
# 
# Уровень статистической значимости: 0.01

# In[26]:


'''Функция, принимает количество успехов и количество попыток двух групп, уровень стат.значимости
рассчитывает пропорции успехов в обеих групах, пропорцию успехов в комбинированном датасете,
проводит z-тест,
возвращает средние конверсии для каждой группы, p_value, результат z-теста
'''

def get_z_test(success_1, success_2, total_1, total_2, alpha):
        # пропорция успехов в первой группе:
    p1 = success_1 / total_1
        # пропорция успехов во второй группе:
    p2 = success_2 / total_2
    
    print(success_1, success_2, total_1, total_2)
        # пропорция успехов в комбинированном датасете:
    p_combined = ((success_1 + success_2)/ 
                      (total_1 + total_2))
        # разница пропорций в датасетах:
    difference = p1 - p2
        # считаем статистику в ст.отклонениях стандартного нормального распределения
    z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * 
                                        (1/total_1 + 1/total_2))
        # задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
    distr = st.norm(0, 1) 
    p_value = (1 - distr.cdf(abs(z_value)))*2
    print('Конверсия первой группы:', "{0:.2f}%".format(success_1/total_1*100))    
    print('Конверсия второй группы:', "{0:.2f}%".format(success_2/total_2*100))  
    print('p-value: {}'.format(p_value))
    if (p_value < alpha):
        print('Отвергаем нулевую гипотезу, между группами есть статистически значимые различия')
    else:
        print('Не отвергаем нулевую гипотезу, между группами нет статистически значимых различий')
    print()

get_z_test(competing_b_recommender_A, competing_b_recommender_B, recommender_A, recommender_B, 0.01)


# Что ж, разница в долях таких пользователей статистически не значима, можем сказать, **что пользователи группы В конкурирующего теста распределены равномерно по группам А и В исследуемого теста.** Оставим пользователей, участвующих в обоих тестах одновременно.

# In[27]:


testig_participants = participants.query('ab_test == "recommender_system_test"')
print('Пользователей, участвующих в "recommender_system_test":', len(testig_participants))


# Пока что мы соответсвуем требованиям ТЗ по ожидаемому количеству участников, однако мы уже можем сформировать первую особенность данных для оценки корректности теста. **Фиксируем:**
# 
# **Встречаются пользователи, участвующие в двух тестах одновременно**. 
# * **Пользователи из группы А конкурирующего теста не должны повлиять на результаты исследуемого теста** (для них не транслировались изменения в тесте "interface_eu_test")
# * **Пользователям из группы B конкурирующего теста изменения в "interface_eu_test" транслировались, но в исследуемом тесте такие пользователи распределены равномерно.**

# #### Проверка на вхождение в обе группы, равномерность распределения по группам

# In[28]:


if testig_participants['user_id'].duplicated().sum() == 0:
    print("Нет дубликатов в 'user_id', каждый пользователь входит только в одну группу")
else:
    print("Встречаются дубликаты в 'user_id', необходима дополнительная проверка")
print()
print('Распределение пользователей по группам теста:')
testig_participants['group'].value_counts()


# Здесь сюрпризов нет: каждый участник теста входит только в одну группу, но численно пользователи распределены не равномерно. **Фиксируем:**
# * каждый участник входит только в одну группу, **нет пересечений по группам**
# * **в группе А на 947 участников больше, чем в группе B**

# ### Проверка дат

# Основные требования: 
# * первая дата пользователя должна попадать в диапазон даты запуска теста и даты остановки набора новых пользователей
# * дата события не должна превышать дату остановки теста
# * время проведения теста не должно совпадать с маркетинговыми и другими активностями
# 
# Сохраним все интересующие нас даты в отдельных переменных и приступим к оценке.

# In[29]:


start_date = dt.datetime.strptime('2020-12-07', "%Y-%m-%d").date()     # начало теста
end_date = dt.datetime.strptime('2021-01-04', "%Y-%m-%d").date()       # окончание теста
end_user_set =  dt.datetime.strptime('2020-12-21', "%Y-%m-%d").date()  # окончание набора новых пользователей


# #### Пользователи, пришедшие после окончания набора новых пользователей

# In[30]:


# сохраним в отдельном списке отобранных пользователей:
testig_user = testig_participants['user_id'].tolist()
# в 'testing_new_user' сохраняем только нужные id
testing_new_user = new_users.query('user_id in @testig_user').sort_values(by='first_date')


# In[31]:


print('Минимальная первая дата пользователя', testing_new_user['first_date'].min())
print('Максимальная первая дата пользователя', testing_new_user['first_date'].max())

if testing_new_user['first_date'].min() >= start_date and testing_new_user['first_date'].max() <= end_user_set:
    print('Все пользователи набраны после старта теста и до дня остановки набора новых пользователей (включительно)')
else:
    print('Встречаются пользователи, набранные за пределами ожидаемого временного диапазона')


# Тут все хорошо, **фиксируем:**
# 
# **Все пользователи собраны в нужный период.**

# #### События, совершенные до старта теста или после его окончания

# In[32]:


# оставляем в testing_events только нужных пользователей
testing_events = events.query('user_id in @testig_user')

print('Минимальная первая дата пользователя', testing_events['date'].min())
print('Максимальная первая дата пользователя', testing_events['date'].max())

if testing_events['date'].min() >= start_date and testing_events['date'].max() <= end_date:
    print('Все события совершены после старта теста и до дня его остановки (включительно)')
else:
     print('Встречаются события, совершенные за пределами ожидаемого временного диапазона')


# В целом, все хорошо, но последнее событие совершено до даты остановки теста, **фиксируем:**
# 
# * **Выходящих за ожидаемый период событий нет**.
# * **Нет событий, произошедших с 31.12 по 04.01**

# ### Распределение пользователей по регионам

# Как мы помним, маркетинговые акции могут распростроняться на разные регионы. `Чтобы понять с какими именно акциями нам нежелательно пересекаться, посмотрим по каким регионам распространены участники теста.`

# In[33]:


testing_new_user_region = testing_new_user.groupby('region')['user_id'].count().sort_values().reset_index()


# In[34]:


fig = px.bar(testing_new_user_region,
             y='region', x='user_id', text='user_id', orientation='h')
fig.update_layout(title='Количество участников теста по регионам',
        title_x = 0.5,
        height=400, width=900)
fig.update_yaxes(title_text = "Регионы")
fig.update_xaxes(title_text = "Количество участниов")

fig.show()


# Большинство пользователей из европейского региона, их количество отвечает требованию ТЗ. Т.к. нас интереесуют изменения конверсий именно европейских пользователей, **удалим из исследования пользователей из других регионов.**

# In[35]:


# Сохраним новый корректный список пользователей
eu_testing_user = testing_new_user.query('region == "EU"')['user_id'].tolist()


# In[36]:


# Сохраним количество  новых пользователей из EU, 
# зарегистрированных в период с даты старта теста до даты окончания набора новых пользователей:
total_ue_new_user = new_users.query('region =="EU" and  @end_user_set >= first_date  >= @start_date')


# In[37]:


print('Доля новых пользователей из EU, участвующих в тесте:',
      "{0:.2f}%".format(len(eu_testing_user)/len(total_ue_new_user)*100))


# На этом этапе мы все еще соответствуем ТЗ. **Фиксируем:**
# 
# **Доля новых пользователей из Европы  соответсвует ожидаемому в ТЗ (15%)**
# 
# 
# 

# #### Проверка пересечения времени теста с региональными маркетинговыми активностями

# **Теперь посмотрим на маркетинговые мероприятия в таком ключе:**
# * распространяется на европейский регион
# * дата начала или дата окончания мероприятия больше даты старта теста

# In[38]:


eu_project = project[project['regions'].str.contains('EU')] 
eu_project.query('start_dt > @start_date or finish_dt>@start_date')


# Во время проведения теста проходила одна промоакция: "Christmas&New Year Promo". Маркетинговое мероприятие может исказить результаты теста, **крайне нежелательно проводить подобные активности в период проведения тестирования.** Также отметим в принципе не самый удачный выбранный период - в предновогодние дни покупательская активность обычно и так выше, чем в остальные. 
# 
# Посмотрим, **сколько событий успели совершить пользователи из разных групп во время проведения промо.** Объединим все таблицы в 'eu_data', сохранив только подходящих нам пользователей

# In[39]:


# сохраняем в eu_testing_participants только пользователей из EU
eu_testing_participants = testig_participants.query('user_id in @eu_testing_user')


# Таблица с распределением по группам для нас - основная, в первую очередь нам важно сохранить именно ее данные, поэтому все таблицы будем присоединять именно к 'eu_testing_participants' по общему столбцу 'user_id'

# In[40]:


# присоединяем 'new_users'
eu_data = eu_testing_participants.merge(new_users, on='user_id', how='left')


# In[41]:


# присоединяем 'events'
eu_data = eu_data.merge(events, on='user_id', how='left')


# In[42]:


display(eu_data.head(3))
eu_data.info()


# Собрали всю необходмую информацию по участникам теста в 'eu_data', видим одинаковое количество пропусков в 'event_dt', 'date' и 'event_name' - **не все пользователи совершали действия.** Более детально рассмотрим этот момент в следующем блоке, **сейчас проанализируем активность каждой из групп в период проведения промо, чтобы принять решение о допустимости пересечения теста с промоакцией**

# In[43]:


eu_data.groupby('date')['event_name'].count().plot(figsize=(10, 5))
plt.grid(True)
plt.xticks(rotation=60)
plt.ylabel('Количество событий')
plt.xlabel('Дата')
plt.title('Количество событий в день по обеим группам');


# В принципе, **нельзя сказать что промоакция как-то сильно повлияла на количество событий** - покупательский интерес во время проведения акции спадает. Посмотрим, как распределены доли таких событий среди всех остальных событий по группам

# In[44]:


# разбиваем пользователей на две группы
eu_a = eu_data.query('group == "A"')
eu_b = eu_data.query('group == "B"')

# оставляем только действия совершенные в период акции по обеим группам
promo_a = eu_a.query('"2021-01-03" >= date >="2020-12-25"')
promo_b = eu_b.query('"2021-01-03" >= date >="2020-12-25"')

promo_a_event = promo_a['event_name'].count()
promo_b_event = promo_b['event_name'].count()
total_a_event = eu_a['event_name'].count()
total_b_event = eu_b['event_name'].count()

print('Группа А')
print('Всего событий:', total_a_event)
print('Событий в период проведения акции:', promo_a_event, ',', "{0:.2f}%".format(promo_a_event/total_a_event*100), 
      'от общего числа')
print('Группа B')
print('Всего событий:', total_b_event)
print('Событий в период проведения акции:', promo_b_event, ',', "{0:.2f}%".format(promo_b_event/total_b_event*100), 
      'от общего числа')


# **А вот пропорциаонально такие события распределены неравномерно.** Однако если акция транслируется обеим группам одновременно, то не стоит исключать период проведения промоакции из анализа. **Фиксируем:**
# 
# * **Во время проведения теста осуществлялась маркетинговая активность**
#     * Глобально проведение акции не повлияло на покупательскую активность
#     * Количество действий, осеществленных в период промо, неравномерно распределено по группам

# ### Все ли пользователи осуществляли действия? 

# В предыдущем блоке мы обратили внимание, что есть пропуски в столбцах, связанных с действиями, **значит, не все участники теста совершали действия.** Изучим этим пропуски.

# In[45]:


without_event = eu_data.query('event_name.isna()')
print('Пользователей, не совершавших действий:', len(without_event), ',',
      "{0:.2f}%".format(len(without_event)/eu_data['user_id'].nunique()*100))


# **Чуть менее половины пользователей, отобранных для теста не совершали никаких действий**. Посмотрим, на них внимательнее

# In[46]:


print('Пользователи, не совершавшие действий, по группам:')
without_event['group'].value_counts()


# **Большинство из таких пользователей относятся к группе B,** что очень плохо - группа и так меньше контрольной.

# In[47]:


without_event['first_date'].value_counts().plot(figsize=(10, 5))
plt.ylabel('Количество пользователей')
plt.xlabel('Дата')
plt.title('В какие дни пришли пользователи, не совершившие ни одного события?');


# Большинство из таких пользователей пришли к нам 13.12. Встречаются и более ранние даты, т.е. н**ельзя сказать, что пользователи пришли к концу теста и просто не успели совершить никаких действий.**
# 
# Пользователям из группы B транслировались некие изменения - могли ли внедренные изменения спровоцировать какие-то технические ошибки для определенного типа устройства?

# In[48]:


without_event_B = without_event.query('group == "B"')
print('Пользователи, не совершавшие действий, распределение по устройствам:')
without_event_B['device'].value_counts()


# Большинство таких пользователей использует Android, как и большинство всех остальных пользователей, так что проблему здесь не выявить. Никаких иных данных по пользователям у нас нет.
# 
# **Посмотрим, в какие дни пришли пользователи, не совершившие никаких действий**

# In[49]:


without_event_A = without_event.query('group == "A"')
without_event_A_day_cnt = without_event_A.groupby('first_date')['user_id'].nunique().reset_index()
without_event_B_day_cnt = without_event_B.groupby('first_date')['user_id'].nunique().reset_index()


# In[50]:


fig = go.Figure()
fig.add_trace(go.Scatter(x=without_event_A_day_cnt['first_date'], y=without_event_A_day_cnt['user_id'],
                    mode='lines+markers',
                    name='A'))
fig.add_trace(go.Scatter(x=without_event_B_day_cnt['first_date'], y=without_event_B_day_cnt['user_id'],
                    mode='lines+markers',
                    name='B'))
fig.update_layout(
    title="Количество действий в день по группам",
    xaxis_title="Дата",
    yaxis_title="Количество действий",
    xaxis = dict(tickvals =without_event_B_day_cnt['first_date']),
    legend=dict(yanchor="top", y=0.9, xanchor="left", x=0.9),
    margin=dict(l=0, r=0, t=30, b=0))
fig.show()


# Видим неравномерно распределение таких пользоватлей по группам - у группы A график обрывается на 13.12, у группы B продолжают набираться пользователи, не совершавшие действий. Вероятно, есть ошибки в логировании или иные проблемы с данными или с использованием приложения, в любом случае, распределение по группам неравномерно, **к сожалению, мы вынуждены исключить таких пользователей, т.к. они никак не участвовали в тесте.**

# In[51]:


eu_data = eu_data.query('event_name.notna()')
print('Всего участников теста:', eu_data['user_id'].nunique())
print('Из группы А:', eu_data.query('group == "A"')['user_id'].nunique())
print('Из группы B:', eu_data.query('group == "B"')['user_id'].nunique())


# Сильно отошли от ожиданий ТЗ. **Фиксируем:**
# * **45% участников не совершили ни одного действий.** Особенностей среди участников не обнаружено
# * Количество участников теста сократилось до **3481** человека, группа А почти в три раза численно превосходит группу B

# ### Ограничение действий по лайфтайму

# Обратимся к разъяснению ТЗ по поводу лайфтайма:
# 
# * **Пользователи должны иметь возможность совершать события в течении двух недель.**
# 
# Т.е. нас интересуют только пользователи успевшие "прожить" 2 недели до даты окончания теста
# 
# * **Мы должны отфильтровать события, которые пользователи совершили после 14 дней от регистрации.**
# 
# Так как нас интересует улучшение метрики только в течении 14 дней от регистрации, мы должны отбросить события, которые произошли после 14 дней от того момента, как был зарегистрирован пользователь, который их совершил. Нам необходимо, чтобы лайфтайм событий, которые будут влиять на наш тест, укладывался в установленный горизонт событий.

# In[52]:


# рассчитываем лайфтайм для каждого события
eu_data['lifetime'] = (eu_data['date'] - eu_data['first_date']).dt.days


# In[53]:


# срезаем события, совершенные после 14-го лайфтайма
eu_data = eu_data.query('lifetime <= 14')


# In[54]:


print('Максимальнаая дата регистрации:', eu_data['first_date'].max())


# Минимальная дата регистрации для нас подходит - **все пользователи пришли за две недели до окончания теста**

# ### Оценка оставшихся пользователей

# In[55]:


print('Всего участников теста:', eu_data['user_id'].nunique())
print('Количество совершенных действий', len(eu_data))
print('Из группы А:', eu_data.query('group == "A"')['user_id'].nunique())
print('Из группы B:', eu_data.query('group == "B"')['user_id'].nunique())
print('Отобрано новых клиентов из EU:',
      "{0:.2f}%".format(eu_data['user_id'].nunique()/len(total_ue_new_user)*100))


# Набор данных включал в себя большое количество пользователей, никак не участвующих в тесте (пользователи не совершали даже 'login', т.е. вообще не открывали приложение). **Исключив их, сильно отошли от ожидаемого количества участников.**

# ### Выводы
# 
# *Соберем все, что мы зафискировали в течении оценки корректности проведения теста*
# 
# **Негативные детали тестирования**
# 
# **1. Встречаются пользователи, участвующие в двух тестах одновременно.**
# 
# Проанализировали распределение по группам конкурирующего и исследуемого теста, оставили таких пользователей:
# 
# * Пользователи из группы А конкурирующего теста **не должны повиять на результаты исслеуемого теста** (для них не транслировались изменения в тесте "interface_eu_test")
# * Пользователям из группы B конкурирующего теста изменения в "interface_eu_test" транслировались, **но в исследуемом тесте такие пользователи распределены равномерно.**
# 
# **2. Во время теста осуществлялась маркетинговая активность**
# 
# Глобально проведение акции не повлияло на покупательскую активность (наблюдаем спад действий в период промо)
# 
# * допущено пересечение с маркетинговой акцией, т.к. **она транслируется обеим группам**
# * количество действий, осеществленных в период промо, **неравномерно распределено по группам**
# 
# **3. Есть пользователи, не совершившие ни одного действия**
# 
# У групп в неравных долях наблюдается набор пользователей, не совершавших действий. У групп А набор таких пользоватлей остановился 15.12, у группы B продолжался до конца периода.
# 
# * **45% участников не совершали действий**
# * такие участники исключены
# 
# **4. Количество участников не соответствует ожидаемым**
# 
# * количество участников сократилось до **3481**, что на 2519 человек меньше ожидаемого
# * всего отобрано **8.22% новых клиентов из EU**
# 
# **5. Участники между группами распределены неравномерно**
# * 2604 входят в группу А
# * 877 входят в группу В
# 
# 
# На основании вышесказанного, можем утверждать, что **тест провден некорректно.** 
# 
# **Резльтаты А/B-тестирования могут быть искажены под влиянием всех 5 пунктов**
# 
# 
# *Из положительных деталей:*
# 
# * каждый участник входит только в одну группу, **нет пересечений по группам**
# * Все пользователи собраны в нужный период
# * Выходящих за период проведения теста событий нет
# * огранили число событий на основании лайфтайма (оставили только те, что были совершены до 14-го дня с момента регистрации) без потери уникальных участников

# ## Исследовательский анализ

# Здесь рассмотрим следующие вопросы:
# 
# * Количество событий на пользователя одинаково распределены в выборках?
# * Как число событий в выборках распределено по дням?
# * Как меняется конверсия в воронке в выборках на разных этапах?
# * Какие особенности данных нужно учесть, прежде чем приступать к A/Bтестированию?

# In[56]:


# сохраним данные по группам в отдельные df
a_group = eu_data.query('group == "A"')
b_group = eu_data.query('group == "B"')


# ### Распределение количества событий на пользователя

# In[57]:


# считаем количество событий по пользователям в каждой из групп
a_per_user = a_group.groupby('user_id')['event_name'].count().reset_index()
b_per_user = b_group.groupby('user_id')['event_name'].count().reset_index()


# In[58]:


fig = go.Figure()
fig.add_trace(go.Histogram(x=a_per_user['event_name'],
                          
                           opacity=0.4,
                           name='А',nbinsx=20))
fig.add_trace(go.Histogram(x=b_per_user['event_name'],
                           
                           opacity=0.4, name='В',nbinsx=20))
fig.update_layout(
    title="Количество действий на одного пользователя по группам",
    xaxis_title="Количество действий",
    yaxis_title="Количество пользователей",
    legend=dict(yanchor="top", y=0.9, xanchor="left", x=0.9),
    barmode='overlay',
    margin=dict(l=0, r=0, t=30, b=0))
fig.show()


# Помня о том, что у группы А численное преимущество, **количество действий на пользователя распределено достаточно равномерно.**
# 
# У группы B крайне редко встречаются пользователи, совершившие более 15 действий. Посмотрим на средние значения по группам:

# In[59]:


print('Среднее количество действий на пользователя:')
print('Группа А:', round(a_per_user['event_name'].mean(),2))
print('Группа В:',round(b_per_user['event_name'].mean(),2))


# Усредненные значения отличаются. **Фиксируем:**
# 
# * **Между группами есть различия в среднем количестве действий на пользователя, что может повлиять на результаты теста теста**

# ### Число событий по дням

# In[60]:


# считаем количество событий по дням в каждой из групп
a_per_day = a_group.groupby('date')['event_name'].count().reset_index()
b_per_day = b_group.groupby('date')['event_name'].count().reset_index()


# In[61]:


fig = go.Figure()
fig.add_trace(go.Scatter(x=a_per_day['date'], y=a_per_day['event_name'],
                    mode='lines+markers',
                    name='A'))
fig.add_trace(go.Scatter(x=b_per_day['date'], y=b_per_day['event_name'],
                    mode='lines+markers',
                    name='B'))
fig.update_layout(
    title="Количество действий в день по группам",
    xaxis_title="Дата",
    yaxis_title="Количество действий",
    xaxis = dict(tickvals =a_per_day['date']),
    legend=dict(yanchor="top", y=0.9, xanchor="left", x=0.9),
    margin=dict(l=0, r=0, t=30, b=0))
fig.show()


# Количество действий в день по группам сильно различается, что ожиданио: группа А имеет численное превосходство в пользователях.
# 
# * динамика действий у обеих групп схожая: рост и спад числа действий по группам приходится на одни и те же дни (за редкими исключениями)
# 
# В целом, такой график малоинформативен, **посмотрим на среднее количество событий в день на одного пользователя по группам**

# In[62]:


# для каждой группы считаем кол-во уникальных пользователей, кол-во событий, рассчитываем среднее кол-во событий на пользователя
a_mean_per_day = a_group.groupby('date').agg({'user_id':'nunique', 'event_name':'count'}).reset_index()
a_mean_per_day['ratio'] = round(a_mean_per_day['event_name'] / a_mean_per_day['user_id'], 2)
b_mean_per_day = b_group.groupby('date').agg({'user_id':'nunique', 'event_name':'count'}).reset_index()
b_mean_per_day['ratio'] = round(b_mean_per_day['event_name'] / b_mean_per_day['user_id'], 2)


# In[63]:


fig = go.Figure()
fig.add_trace(go.Scatter(x=a_mean_per_day['date'], y=a_mean_per_day['ratio'],
                    mode='lines+markers',
                    name='A'))

fig.add_trace(go.Scatter(x=b_mean_per_day['date'], y=b_mean_per_day['ratio'],
                    mode='lines+markers',
                    name='B'))

fig.update_layout(
    title="Среднее количество событий в день на одного пользователя",
    xaxis_title="Дата",
    yaxis_title="Среднее количество событий",
    xaxis = dict(tickvals =a_per_day['date']),
    legend=dict(yanchor="top", y=0.9, xanchor="left", x=0.9),
    margin=dict(l=0, r=0, t=30, b=0))
fig.show()


# За исключением несколькоких пересечний, **у группы А среднее количество событий на пользователя стабильно выше**

# ### Как меняется конверсия в воронке в выборках на разных этапах

# Сначала построим таблицу для каждой группы и оценим сколько раз произошло каждое из действий.

# In[64]:


a_funnel = a_group.groupby('event_name')['user_id'].nunique().sort_values(ascending=False).reset_index()
a_funnel


# Видим, что ожидаемая воронка не соблюдается: событие **'purchase' происходит чаще, чем событие 'product_cart'**. Мы еже обращали внимание на такое распределение числа действий на этапе предобработки: **видимо, есть возможность совершить покупку, не заходя в корзину.** 
# 
# *Для графика воронки расположим события в ожидаемом порядке: "зашел - открыл карточку - добавил в корзину - купил"*

# In[65]:


a_funnel = a_funnel.reindex([0,1,3,2])


# In[66]:


b_funnel = b_group.groupby('event_name')['user_id'].nunique().sort_values(ascending=False).reset_index()
b_funnel


# У группы В ситуация аналогичная. `Построим графики для обеих групп.`

# In[67]:


b_funnel = b_funnel.reindex([0,1,3,2])


# In[68]:


fig = make_subplots(rows=1, cols=2, subplot_titles=['А', 'В'], shared_yaxes=True)

trace0 = go.Funnel(y=a_funnel['event_name'], x=a_funnel['user_id'])
trace1 = go.Funnel(y=b_funnel['event_name'], x=b_funnel['user_id'])
fig.update_layout(title='Воронки событий по группам', showlegend=False)

fig.append_trace(trace0, 1, 1)
fig.append_trace(trace1, 1, 2)
fig.update_yaxes(title='События', col=1, row=1)
fig.update_xaxes(title='Средняя стоимость', col=1, row=1)

fig.update_xaxes(title='Средняя стоимость', col=2, row=1)
fig.update_layout(showlegend=False)
fig.show()


# Рассмотрим события 'product_cart' и 'purchase' вне зависимость друг от друга, т.к. мы уже определили. что покупка может совершаться без участия корзины.
# 
# **Группа А**
# * карточку продукта открывают 64.7%
# * в корзину из карточки добавляют 46.4% или 13.2% от всех пользователей
# * покупку из просмотра карточки (с возможным заходом в корзину) осуществляют 49.4% или 14.1% от всех пользователей
# 
# **Группа В**
# * карточку продукта открывают 56.3%
# * в корзину из карточки добавляют 49.5% или 13.1% от всех пользователей
# * покупку из просмотра карточки (с возможным заходом в корзину) осуществляют 50.5% или 13.4% от всех пользователей
# 
# **Группы различаются по конверсиям**
# * Участники группы А чаще открывают карточки
# * В корзину из карточки чаще добавляют участники группы В
# * После просмотра карточки покупку чаще осуществляют участники группы В (но нельзя оценить, заходили ли они в корзину перед покупкой)
# * Конверсия в покупку выше у группы А

# #### Кумулятивные конверсии

# Оценим кумулятивные конверсии в каждое из целевых действий у обеих групп.
# * получим кумулятивные значения уникальных посетителей и пользователей, совершивших действия
# * посмотрим как они отличаются в динамике
# * посмотрим, наблюдается ли относительный прирост у группы В над А
# 
# *Сможем оценить период с начала теста до 21.12, т.к. после этой даты новых пользователей не набиралось*

# In[69]:


'''Функция, принимает таблицу, названия событий
фильтрует таблицу по событиям, возвращает три отфильтрованные таблицы'''
def make_query(df, event_1, event_2, event_3):
    filtred_1 = df.query(f'event_name == "{event_1}"')
    filtred_2 = df.query(f'event_name == "{event_2}"')
    filtred_3 = df.query(f'event_name == "{event_3}"')
    return filtred_1, filtred_2, filtred_3


# In[70]:


product_page, product_cart, purchase = make_query(eu_data, 'product_page', 'product_cart', 'purchase')


# In[71]:


# создаем массив уникальных пар значений дат и групп теста
datesGroups = eu_data[['date','group']].drop_duplicates()


# In[72]:


# получаем агрегированные кумулятивные по дням данные о посетителях 
visitors_aggregated = datesGroups.apply(lambda x: eu_data[np.logical_and(eu_data['date'] <= x['date'],
                                                                         eu_data['group'] == x['group'])]
                                       .agg({'date' : 'max', 
                                             'group' : 'max', 
                                             'user_id' : 'nunique'}), axis=1).sort_values(by=['date','group'])


# In[73]:


'''Функция, принимает таблицу,
собирает аггрегигованные данные о количестве совершивгих событие пользоваелях,
возвращает агргрегированную таблицу'''
def get_aggregated_df(df):
    event_aggrerated = datesGroups.apply(lambda x: df[np.logical_and(df['date'] <= x['date'],
                                                                     df['group'] == x['group'])]\
                                     .agg({'date' : 'max',
                                           'group' : 'max', 
                                           'user_id' : 'nunique'}), axis=1).sort_values(by=['date','group'])
    return event_aggrerated


# In[74]:


# применяем get_aggregated_df к отфильтрованным ранее таблицам:
product_page_aggregated = get_aggregated_df(product_page)
product_cart_aggregated = get_aggregated_df(product_cart)
purchase_aggregated = get_aggregated_df(purchase)


# In[75]:


#переиминовываем столбцы в полученных таблицах:
product_page_aggregated = product_page_aggregated.rename(columns={'user_id':'product_page'})
product_cart_aggregated = product_cart_aggregated.rename(columns={'user_id':'product_cart'})
purchase_aggregated = purchase_aggregated.rename(columns={'user_id':'purchase'})


# Наконец, создаем таблицу с кумулятивными значениями в 'eu_cumulative' объединим таблицу с визитами и таблицы с аггрегированными данными по каждому ключевому событию.

# In[76]:


# присоединем 'product_page_aggregated'
eu_cumulative = visitors_aggregated.merge(product_page_aggregated, how='left', on=['date', 'group'])


# In[77]:


# присоединем 'product_cart_aggregated'
eu_cumulative = eu_cumulative.merge(product_cart_aggregated, how='left', on=['date', 'group'])


# In[78]:


# присоединям 'purchase_aggregated':
eu_cumulative = eu_cumulative.merge(purchase_aggregated, how='left', on=['date', 'group']) 


# In[79]:


eu_cumulative = eu_cumulative.rename(columns={'user_id':'total'})
#срезаем даты до горизонта анализа:
eu_cumulative = eu_cumulative.query('date < "2020-12-22"')
# рассчитываем кумулятивную конверсию по каждому событию:
eu_cumulative['product_page_cr'] = round(eu_cumulative['product_page'] / eu_cumulative['total'], 2)
eu_cumulative['product_cart_cr'] = round(eu_cumulative['product_cart'] / eu_cumulative['total'] , 2)
eu_cumulative['purchase_cr'] = round(eu_cumulative['purchase'] / eu_cumulative['total'], 2)


# In[80]:


# создаем отдельные таблицы для каждой из групп:
a_cumulative = eu_cumulative.query('group == "A"')
b_cumulative = eu_cumulative.query('group == "B"')


# In[81]:


# создаем общую таблицу для возможности рассчета относительного прироста:
merge_cumulative = a_cumulative[['date', 'product_page_cr', 'product_cart_cr', 'purchase_cr']]    .merge(b_cumulative[['date', 'product_page_cr', 'product_cart_cr', 'purchase_cr']], left_on='date', 
           right_on='date', how='left', suffixes=['_A', '_B'])


# In[82]:


# рассчитываем относительный прирост группы B над A по всем конверсиям
merge_cumulative['relative_product_page'] = merge_cumulative['product_page_cr_B'] / merge_cumulative['product_page_cr_A']-1
merge_cumulative['relative_product_cart'] = merge_cumulative['product_cart_cr_B'] / merge_cumulative['product_cart_cr_A']-1
merge_cumulative['relative_purchase'] = merge_cumulative['purchase_cr_B'] / merge_cumulative['purchase_cr_A']-1


# Собрали в 'eu_cumulative' кумулятивные конверсий по всем типам событий, а в 'merge_cumulative' данные об относительном приросте каждой из конверсий. Посмотрим на отличия групп.

# In[83]:


'''Функция, принимает названия столбцов и название конверсии для заголовка,
отрисовывает графики кумулятивной конверсии по группам и график относительного прироста'''

def make_scatter(col_1, col_2, cr_name):
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=a_cumulative['date'], y=a_cumulative[col_1],
                    mode='lines+markers',
                    name='A'))
    fig.add_trace(go.Scatter(x=b_cumulative['date'], y=b_cumulative[col_1],
                    mode='lines+markers',
                    name='B'))
    fig.update_layout(
        height=300, width=900,
        title=f"Кумулятивная конверсия в {cr_name}",
        xaxis_title="Дата",
        yaxis_title="Конверсия",
        xaxis = dict(tickvals =a_cumulative['date']),
        legend=dict(yanchor="top", y=0.9, xanchor="left", x=0.9),
        margin=dict(l=0, r=0, t=30, b=0))
    fig.show()
    
    fig = px.line(x=merge_cumulative['date'], y=merge_cumulative[col_2])
    fig.add_hline(y=0, line_width=3, line_dash="dash", line_color="green")
    fig.update_layout(
        height=300, width=900,
        title= f"Относительное изменение кумулятивной конверсии в {cr_name} группы В к группе А",
        xaxis_title="Дата",
        yaxis_title="Относительный прирост",
        xaxis = dict(tickvals = a_cumulative['date']),
        legend=dict(yanchor="top", y=0.9, xanchor="left", x=0.9),
        margin=dict(l=0, r=0, t=30, b=0))

    fig.show()


# In[84]:


make_scatter("product_page_cr", "relative_product_page", '"product_page"')


# **Конверсия в просмотр карточки:**
# 
# * Группа B весь стабильно и значительно показывает результат хуже, чем группа А
# * **Улучшение метрики у группы В относительно группы А не наблюдается.** В период с 18.12 по 21.12 относительное падение конверсии у группы по отношению к А составляет более 12%

# In[85]:


make_scatter("product_cart_cr", "relative_product_cart", '"product_cart"')


# **Конверсия в добавление в корзину:**
# 
# * Начиная с 9.12 до конца периода конверсия группы B стабильно ниже, чем конверсия группы А
# * **Улучшения метрики у группы B по отношению к группе А начиная с 9.12 не наблюдается.** Под конец периода группа В отстает от группы А на ~6.5%

# In[86]:


make_scatter("purchase_cr", "relative_purchase", '"purchase"')


# **Конверсия в покупку:**
# 
# * До 15.12 группа B демонстрировала конверсию выше, чем группа А
# * В первой половине наблюдаем относительный прирост конверсии группы В более, чем на 10%. **К концу периода конверсия группы В относительно ниже.**

# **Итого:** в период 7.12-21-12 конверсии в просмотр карточки и добавление в корзину у группы стабильно ниже. Относительный прирост в конверсии в покупку наблюдается только в первой половине периода, далее конверсия группы В проигрывает группе А.

# ### Доли целевых действий в каждый из лайфтаймов

# Проанаоизируем лайфтаймы. Посмотрим, **сколько пользователей (в долях) из каждой группы совершает целевые действия в каждый из лайфтаймов** - так мы сможем оценить, какая группа обычно быстрее совершает одно из целевых действий.

# In[87]:


'''Функция, принимает таблицу и названия события
фильтрует таблицу по событию, группирует по лайфтайму, подсчитывает количество уникальных пользователей,
рассчитывает долю, возвращает отфильтрованную таблицу'''
def make_lifetime_event(df, event):
    group_event = df.query(f'event_name == "{event}"')
    lifetime_event = group_event.groupby('lifetime')['user_id'].nunique().reset_index()
    lifetime_event['ratio'] = round(lifetime_event['user_id'] / df['user_id'].nunique()*100,2)
    return lifetime_event


# In[88]:


a_lifetime_pp = make_lifetime_event(a_group, 'product_page')
a_lifetime_pc = make_lifetime_event(a_group, 'product_cart')
a_lifetime_pur = make_lifetime_event(a_group, 'purchase')

b_lifetime_pp = make_lifetime_event(b_group, 'product_page')
b_lifetime_pc = make_lifetime_event(b_group, 'product_cart')
b_lifetime_pur = make_lifetime_event(b_group, 'purchase')


# In[89]:


'''Функция, принимает две таблицы и название события,
отрисовывает графики'''
def make_lifetime_scatter (df_1,df_2, event):
    fig = go.Figure()
    fig.add_trace(go.Scatter(x = df_1['lifetime'], y = df_1['ratio'], name='A'))
    fig.add_trace(go.Scatter(x = df_2['lifetime'], y = df_2['ratio'], name='B'))
    fig.update_layout(
        height=400, width=900,
        title= f'Доли пользователей, совершивших "{event}"',
        xaxis_title="Лайфтайм",
        yaxis_title="Доля пользователей, %",
        xaxis = dict(tickvals = a_lifetime_pp['lifetime']),
        legend=dict(yanchor="top", y=0.9, xanchor="left", x=0.9),
        margin=dict(l=0, r=0, t=30, b=0))
    fig.show()


# In[90]:


make_lifetime_scatter(a_lifetime_pp, b_lifetime_pp, 'product_page')


# * **Пользователи обоих групп чаще всего совершают просмотр карточек в первый же день** (в нулевой лайфтайм)
# * **Пользователи из группы А в первый день совершают события чаще,** чем пользователи из группы В
# * Группа В в целом менее активна, уже на первый лайфтайм 78% пользователей перестают открывать карточки

# In[91]:


make_lifetime_scatter(a_lifetime_pc, b_lifetime_pc, 'product_cart')


# * Доли пользователей группы B стабильно ниже (за исключением нескольких пересечений)
# * Пользователи обеих групп чаще всего совершают добавление в корзину в первый же день, **однако у пользоваталей группы А доля таких пользователей выше**
# * Доли обеих групп практически сравниваются на 7-й лайфтайм, однако группа **A демонстрирует заметно лучший результат на 1-3 лайфтаймы**

# In[92]:


make_lifetime_scatter(a_lifetime_pur, b_lifetime_pur, 'purchase')


# * снова **преимущество за группой A** - почти 32% совершают первую покупку в первый день, у группы B конверсия 28%.
# * группа А показывает результат выше в 0-11 лайфтаймы, **в начале "жизни" (0-6 лайфтаймы) положительный отрыв от группы В очевиден**

# ### Выводы

# **Наблюдается преимущества группы А над группой В:**
# 
# * выше среднее количество действий на одного пользователя (6.9 против 5.53)
# * пользователи совершили ощутимо больше событий за период (хотя динамика по дням у групп схожая)
# * пользователи чаще совершают конверсию в просмотр карточки и в покупку
# * в период с 7.12-21.12 кумулятивная конверсия лучше: 
#     * результаты группы B в конверсии в просмотр карточки и добавление в корзину стабильно ниже, чем у группы А
#     * конверсия в покупку во второй половине периода так же ниже у группы B
# * пользователи чаще совершают целевые действия в первые дни жизни и в целом ведут себя активнее на протяжении всех 14 дней
# 
# **Резюмируем: группа А имеет очевидные преимущества перед группой B,** что наверняка отразится на результатах теста.

# ## Статистический анализ

# Снова обратимся к ТЗ, чтобы корректно провести тест:
# 
# * ожидаемый эффект: за 14 дней с момента регистрации пользователи покажут улучшение каждой метрики не менее, чем на 10%,
# * проверяется разница в конверсии от начального этапа воронки.
# 
# Отберем для каждой группы количество участников, совершивших 'login' и среди них посчитаем долю совершивших каждое из целевых событий.
# 
# Для проверки каждой из конверсий сформулируем одни и те же гипотезы:
# 
# * **Нулевая гипотеза (Н0):** Между группами **нет** статистически значимых различий **(группы равны)**
# * **Альтернативная гипотеза (Н1):** Между группами **есть** статистически значимые различия **(группы не равны)**
# 
# Установим уровень статистической значимости в **0.05**
# 
# При каждой проверке какой-либо выборки из данных, мы увеличиваем вероятность получить ошибку. **Применим поправку Бонферрони:** разделим уровень стат.значимости на количество сравнений внтури групп (3)

# In[93]:


'''Функция, принимает таблицу, 4 вида событий,
подсчитывает количество уникальных пользователей для каждого из событий,
возвращает численные результаты'''
def count_users(df, event_1, event_2, event_3, event_4):
    count_1 = df.query(f'event_name == "{event_1}"')['user_id'].nunique()
    count_2 = df.query(f'event_name == "{event_2}"')['user_id'].nunique()
    count_3 = df.query(f'event_name == "{event_3}"')['user_id'].nunique()
    count_4 = df.query(f'event_name == "{event_4}"')['user_id'].nunique()
    return count_1, count_2, count_3, count_4


# In[94]:


a_login, a_product_page, a_product_cart, a_purchase = count_users(a_group, 'login', 'product_page', 'product_cart', 'purchase')
b_login, b_product_page, b_product_cart, b_purchase = count_users(b_group, 'login', 'product_page', 'product_cart', 'purchase')


# In[95]:


alpha = 0.05
print('Событие: просмотр карточки')
print()
get_z_test(a_product_page, b_product_page, a_login, b_login, alpha/3)


# **Результат группы А - выше, разница статистически значима**

# In[96]:


print('Событие: добавление в корзину')
print()
get_z_test(a_product_cart, b_product_cart, a_login, b_login, alpha/3)


# **Разница между группами статистически не значима, но средняя конверсия группы В ниже, что не соответствует ожиданиям тестирования**

# In[97]:


print('Событие: покупка')
print()
get_z_test(a_purchase, b_purchase, a_login, b_login, alpha/3)


# **Разница между группами статистически не значима, но средняя конверсия группы В ниже, что не соответствует ожиданиям тестирования**

# ## Выводы, решение по тесту

# Обработаны 4 полученных датасета. 
# 
# # Замечания по проведению А/В-тестирования:
# 
# **1. Есть пересечения с конкурирующим тестом**
# 
# Некорректно проводит несколько тестов на одних и тех же пользователях. Во избежание больших потерь в количестве уникальных пользователей принято решение оставить участников конкурирующего теста т.к.:
# * участники из группы А конкурирующего теста не должны быть подвержену его влиянию, т.к. для них не транслировались изменения
# * доли участников из группы В конкурирующего теста распределены в раном соотношении в исследуемом тесте
# 
# **2. Группы изначально неравны количественно**
# 
# До всех срезов в группе A насчитывали 3824 участников, в B 2877
# 
# **3. Нет событий проиошедних после 30.12**
# 
# При этом тест продолжался до 04.01
# 
# **4. Во время проведения теста проходила маркетинговая активность**
# 
# Глобально акция не повлияла на поведение пользователей, но доли событий этот период распределны по группам неравномерно (в группе А событий больше, чем в группе В
# 
# **5. 45.19% пользователей не совершили ни одного действия**
# 
# Не наблюдается каких-то закономерностей в их характеристиках, таких пользователей пришлось удалить из анализа, т.к. фактически они не принимали участие в тестировании
# 
# **6. Количество участников не соответсвует ожиданиям**
# 
# После сокращения числа неактивных пользователей:
# * Всего участников теста: 3481
# * Отобрано новых клиентов из EU: 8.22%
# * Количество совершенных действий 22828 (количество событий сокращено согласно ТЗ: остались только пользователи, успевшие "прожить" 14 дней и события, не произошедшие до 14-го лайфтайма)
# 
# **7. ИТОГОВЫЕ ГРУППЫ РАСПРЕДЕЛЕНЫ НЕРАВНОМЕРНО**
# 
# * участников из группы А: 2604
# * участников из группы B: 877
# 
# Принимая во внимание все 6 пунктов:
# 
# # Оценка проведения теста: тест нельзя назвать корретным
# 
# 
# По имеющимся данным проведен исследовательский анализ. 
# 
# # Результаты исследовательского анализа
# 
# **Однозначное преимущество группы А над В.**
# * Больше среднее количество действий на пользователя: 6.9 против 5.53
# * ощутимо больше действий в день
# * выше среднее количество событий в день на пользователя
# * выше конверсия в открытие карточки и в покупку
# * кумулятивная конверсия в каждое из целевых действий: конверсия А превышает конверсию B
# * доли целевых действий в каждый из лайфтаймов: пользователи группы А чаще совершают целевые действия в первые "дни жизни"
# 
# *Единственное замеченное преимущество группы В:* выше конверсия в добавление корзину и ее прирост по отношению к группе А в начале проведения теста (после середины декабря конверсия А превышает конверсию В)
# 
# # Результаты тестирования
# 
# *Конверсии рассчитываются от начала воронки ('login') согласно ТЗ*
# 
# **1. Конверсия в просмотр карточки**
# * А: 64.71%
# * В: 56.28%
# * p-value: 8.196
#     
# **Победа за группой А**
# 
# **2. Конверсия в добавление в корзину**
# * А: 30.03%
# * В: 27.85%
# * p-value: 0.222
# 
# **Между группами нет статистически значимой разницы**
# 
# 
# **3. Конверсия в покупку**
# * А: 31.99%
# * В: 28.42%
# * p-value: 0.049
# 
# **Между группами нет статистически значимой разницы**
# 
# **Учитывая результаты тестирования необходимо зафиксировать победу группы А и остановить тест, НО:**
# 
# * к результатам теста стоит относиться скептически, т.к. группа В в связи с некорректной разбивкой не показала должной активности
# * группа В не показала ожидаемого прироста метрик, но можем ли мы доверять результатам теста с такой разбивкой по группам?
# 
# # Решение по тесту: рекомендуется провести тест заново, учитывая все описанные замечания по оценке корректности.
